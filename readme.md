# Awesome-llm-unlearning

A collection of papers and resources about Machine Unlearning on LLMs.

Large language models (LLMs) have demonstrated remarkable capabilities across various tasks, but their training typically requires vast amounts of data, raising concerns in legal and ethical domains. Issues such as potential copyright disputes, data authenticity, and privacy concerns have been brought to the forefront. Machine unlearning offers a potential solution to these challenges, even though it presents new hurdles when applied to LLMs. In this repository, we aim to collect and organize surveys, datasets, approaches, and evaluation metrics pertaining to machine unlearning on LLMs, with the hope of providing valuable insights for researchers in this field.

## Survey

| Paper Title                                                  | Venue | Year    |
| ------------------------------------------------------------ | ----- | ------- |
| [Right to be Forgotten in the Era of Large Language Models: Implications, Challenges and Solutions](https://arxiv.org/abs/2307.03941) | arXiv | 2023.07 |
| [Knowledge Unlearning for LLMs: Tasks, Methods, and Challenges](https://arxiv.org/pdf/2311.15766.pdf) | arXiv | 2023.11 |
| [Machine Unlearning of Pre-trained Large Language Models]()  | arXiv | 2024.02 |
| [Rethinking Machine Unlearning for Large Language Models](https://arxiv.org/pdf/2402.08787.pdf) | arXiv | 2024.02 |



## Methods

| Paper Title                                                  | Key words                                  | Paper with codes                                     | Venue        | Time    |
| ------------------------------------------------------------ | ------------------------------------------ | ---------------------------------------------------- | ------------ | ------- |
| [Whoâ€™s Harry Potter? Approximate Unlearning in LLMs](https://arxiv.org/abs/2310.02238) | **Approximate Unlearning**                 | -                                                    | arXiv        | 2023.10 |
| [DEPN: Detecting and Editing Privacy Neurons in Pretrained Language Models](https://arxiv.org/abs/2310.20138) | **Model Editing**                          | -                                                    | EMNLP 2023   | 2023.10 |
| [Unlearn What You Want to Forget: Efficient Unlearning for LLMs](https://arxiv.org/pdf/2310.20150v1.pdf) | **Adapter**                                | https://github.com/SALT-NLP/Efficient_Unlearning/    | EMNLP 2023   | 2023.10 |
| [Large Language Model Unlearning](https://arxiv.org/pdf/2310.10683.pdf) |                                            | https://github.com/kevinyaobytedance/llm_unlearn     | ICLR 2024    | 2023.10 |
| [Towards Efficient and Effective Unlearning of Large Language Models for Recommendation](https://arxiv.org/pdf/2403.03536.pdf) | **Using LLM Unlearning in Recommendation** | https://github.com/justarter/E2URec                  | arXiv        | 2024.03 |
| [Unlearning Bias in Language Models by Partitioning Gradients](https://aclanthology.org/2023.findings-acl.375.pdf) | MLMs Unlearning                            | https://github.com/CharlesYu2000/PCGU-UnlearningBias | ACL-Findings | 2023    |



## Evaluation

### MIA(Member Inference Attack)

| Paper Title                                                  | Key words               | Venue | Year    |
| ------------------------------------------------------------ | ----------------------- | ----- | ------- |
| [DETECTING PRETRAINING DATA FROM LARGE LANGUAGE MODELS](https://arxiv.org/abs/2310.16789) | pretrain data detection | arXiv | 2023.10 |
| [Practical Membership Inference Attacks against Fine-tuned Large Language Models via Self-prompt Calibration](https://arxiv.org/abs/2311.06062) | finetune data detection | arXiv | 2023.11 |

### Benchmarks & Datasets

| Paper Title                                                  | Key words | Venue | Year    |
| ------------------------------------------------------------ | --------- | ----- | ------- |
| [TOFU: A Task of Fictitious Unlearning for LLMs](https://arxiv.org/pdf/2401.06121.pdf) |           | arXiv | 2024.01 |
| [Machine Unlearning of Pre-trained Large Language Models](https://arxiv.org/pdf/2402.15159.pdf) |           | arXiv | 2024.02 |

