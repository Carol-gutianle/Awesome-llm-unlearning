# Machine Unlearning on LLMs

A collection of papers and resources about Machine Unlearning on LLMs.

Large language models (LLMs) have demonstrated remarkable capabilities across various tasks, but their training typically requires vast amounts of data, raising concerns in legal and ethical domains. Issues such as potential copyright disputes, data authenticity, and privacy concerns have been brought to the forefront. Machine unlearning offers a potential solution to these challenges, even though it presents new hurdles when applied to LLMs. In this repository, we aim to collect and organize surveys, datasets, approaches, and evaluation metrics pertaining to machine unlearning on LLMs, with the hope of providing valuable insights for researchers in this field.

## Survey

| Paper Title | Venue | Year |
| ----------- | ----- | ---- |



## Datasets



## Approaches

| Paper Title                                                  | Key words                  | Paper with codes                                  | Venue      | Time    |
| ------------------------------------------------------------ | -------------------------- | ------------------------------------------------- | ---------- | ------- |
| [Whoâ€™s Harry Potter? Approximate Unlearning in LLMs](https://arxiv.org/abs/2310.02238) | **Approximate Unlearning** | -                                                 | arXiv      | 2023.10 |
| [DEPN: Detecting and Editing Privacy Neurons in Pretrained Language Models](https://arxiv.org/abs/2310.20138) | **Model Editing**          | -                                                 | EMNLP 2023 | 2023.10 |
| [Unlearn What You Want to Forget: Efficient Unlearning for LLMs](https://arxiv.org/pdf/2310.20150v1.pdf) | **Adapter**                | https://github.com/SALT-NLP/Efficient_Unlearning/ | EMNLP 2023 | 2023.10 |
| [Large Language Model Unlearning](https://arxiv.org/pdf/2310.10683.pdf) |                            | https://github.com/kevinyaobytedance/llm_unlearn  | ICLR 2024  | 2023.10 |





## Evaluation Metrics

### MIA(Member Inference Attack)

| Paper Title                                                  | Key words               | Venue | Year    |
| ------------------------------------------------------------ | ----------------------- | ----- | ------- |
| [DETECTING PRETRAINING DATA FROM LARGE LANGUAGE MODELS](https://arxiv.org/abs/2310.16789) | pretrain data detection | arXiv | 2023.10 |
| [Practical Membership Inference Attacks against Fine-tuned Large Language Models via Self-prompt Calibration](https://arxiv.org/abs/2311.06062) | finetune data detection | arXiv | 2023.11 |